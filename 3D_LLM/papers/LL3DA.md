LL3DA: Visual Interactive Instruction Tuning for  Omni-3D Understanding, Reasoning, and Planning
## 1. 研究目标

- 开发能够在复杂多样的 3D 环境中理解、推理和规划的 LMM
- 问题：
	- 3D 场景的排列不变点云 3D 表示的需求
- 现有方法：
	- 多视图图像
	- 将 2D 特征投影到 3D 空间作为 3D 场景表示
		- 会导致巨大的计算开销和性能下降

## 2. 主要贡献

- LL3DA：
	- 一种大型语言 3D 助手
	- 采用点云作为直接输入，并对文本指令和视觉提示做出响应

## 3. 先前工作

- 3d专家模型
	- 下游任务
		- 3D QA
		- 3D视觉基础、
		- 3D密集字幕
	- 缺陷
		- 监督有限，很难扩大规模以获得更好的性能
- 3DLLM
	- LLM 驱动。聚合了 3D 特征的多视图特征，呈现出机器可以理解各种 3D 对象和场景并遵循人类生成的文本指令的强大能力。
- 提取多视图特征
	- 会导致巨大的计算开销，并且忽略了基本的几何属性。
- 纯文本
	- 常常会导致歧义，尤其是在杂乱且复杂的 3D 环境中。

## 4. 模型介绍

