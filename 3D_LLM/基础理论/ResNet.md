>CVPR 2016

- Resnet在cnn图像方面有着非常突出的表现，它利用 **shortcut 短路连接**，解决了深度网络中**_模型退化_**的问题。

- 网络中的亮点
	1. 超深的网络结构（超过1000层）。  
	2. 提出**residual（残差结构）模块**。  
	3. 使用Batch Normalization加速训练（丢弃dropout）。

- 为什么采用residual?
	- 在ResNet提出之前，所有的神经网络都是通过**卷积层和池化层的叠加**组成的。
	- 过度堆叠出现 梯度消失和梯度爆炸
		- 梯度**消失**：若每一层的误差梯度小于1，反向传播时，网络越深，梯度越趋近于0  
		- 梯度**爆炸**：若每一层的误差梯度大于1，反向传播时，网络越深，梯度越来越大

- ResNet残差网络
	- 为了解决深层网络中的**退化问题**，可以人为地让神经网络某些层**跳过下一层神经元的连接**，隔层相连，弱化每层之间的强联系。这种神经网络被称为**残差网络 (ResNets)**。