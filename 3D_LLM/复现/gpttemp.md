在这篇论文中，3D-LLM模型确实采用了预训练+微调的模式。具体来说：

1. **预训练大模型的获取**：
    
    - 3D-LLM利用2D预训练的视觉-语言模型（VLMs）作为其骨干网络，如Flamingo和BLIP-2。这些2D VLMs已经在大规模的图像-文本对上进行了预训练，能够很好地处理2D图像和文本之间的关系。
    - 为了将3D特征与这些2D VLMs对齐，研究者们设计了一个3D特征提取器，该提取器可以从渲染的多视角图像中提取3D特征，并将其映射到与2D预训练特征相同的空间中。
2. **微调过程**：
    
    - **构建微调数据集**：研究者们通过三种独特的提示机制（boxes-demonstration-instruction based prompting, ChatCaptioner based prompting, 和 revision based prompting）从3D场景中生成了大量的3D-语言数据，包括但不限于3D描述、密集描述、3D问答、任务分解、3D定位、3D辅助对话、导航等。这些数据集覆盖了超过30万对3D-语言对，用于训练3D-LLM。
    - **微调方式**：在微调过程中，3D-LLM模型使用标准的语言建模损失来输出响应。具体来说，3D特征和输入的语言提示一起输入到3D-LLM中，模型通过优化预测输出与真实答案之间的差异来进行训练。此外，为了更好地捕捉3D空间信息，还引入了3D定位机制，通过添加位置嵌入和位置标记来增强模型的空间感知能力。

通过这种预训练+微调的方式，3D-LLM不仅能够高效地利用现有的2D预训练模型，还能在特定的3D任务上表现出色，如在ScanQA数据集上的实验结果所示，3D-LLM在多个评估指标上显著优于现有的基线模型。