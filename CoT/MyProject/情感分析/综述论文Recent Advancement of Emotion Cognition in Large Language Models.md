## 1. introduction
大语言模型（LLM）中的情绪认知对于提高各种应用程序的性能至关重要，例如社交媒体，人类计算机互动和心理健康评估。

我们探讨了当前的研究landscape，这些landscape主要围绕
1. 情绪分类
2. 情感丰富的反应产生
3. 心理评估理论

在本文中，我们详细介绍了<mark style="background: #FFB86CA6;">LLM在情绪认知中的最新进展的详细调查</mark>。探究了领域中研究的潜在研究方向，包括无监督的学习方法以及更复杂和<mark style="background: #FFB86CA6;">可解释的情感认知LLM的发展</mark>。我们还讨论了高级方法，例如用于提高LLM的情绪认知能力的对比学习

具有情感认知能力使LLM可以更加与人类价值观保持一致，从而增强其在情绪相关的下游任务中的表现。

一些挑战：
从LLM角度来讲：
1. 过度依赖注释数据
2. 难以处理复杂的情绪
3. 解释情绪认知中LLM的决策过程

从情绪分析上讲：
1. 问题的独特性，这表明文本中的情绪是抽象的，需要深刻的理解； 
2. 方法论复杂性，表明情绪超出了分类或产生，需要定制的策略和定量评估；
3. 任务的多样性，这表明情绪任务如问答和对话需要各种方法和有效性措施。

然后，我们在LLM中引入了两个典型的方向以进行情感认知：
1. 情绪评估
2. 情绪增强

情绪认知与人类情感心理学高度相关，不仅需要计算方法和技术，而且需要对心理理论的深刻理解和应用。

在我们的综述中，我们强调将心理学观点结合起来，特别是基于Ulric Neisser的认知心理学理论（Neisser，2014年）

贡献：
1. 从问题定义，方法论和应用领域的角度来看，我们对情绪认知的主要挑战进行了深入的分析。
2. 我们根据认知心理学理论的七个阶段将作品分类为情感领域，使特定任务与人类认知过程更好地保持一致。
3. 我们对情绪认知的未来研究方向进行了深入的讨论，旨在激发LLMS情感计算领域的进一步进步。

---
更具体的任务分类：
i）判别任务：包括在各种数据集上进行的情感分类和情感识别（张等人，2023 年；卡内罗斯 - 普拉多等人，2023 年；拉特杰等人，2023 年）。  
ii）生成任务：评估大语言模型的情感生成能力（林奇等人，2023 年；谢等人，2023 年；内森・克拉帕奇，2023 年）。  
iii）心理理论任务：关注大语言模型推断和复制人类心理状态的能力（特罗特等人，2023a；萨普等人，2022 年；甘地等人，2023 年）。  
iv）高阶任务：包括角色扮演、幽默理解、共情生成以及决策制定（江等人，2023 年；延奇和克尔斯廷，2023 年；李等人，2022 年；金等人，2022 年）。

对大语言模型的提升方法可分类如下：  
i）上下文学习：融入情感标签和上下文示例以提高情感识别能力（孙等人，2023 年；雷等人，2023 年；李等人，2022 年）。  
ii）微调：提升在心理健康预测和情感分析等任务中的表现（徐等人，2023 年；赫里和卡里米，2023 年；彭等人，2023 年；宾茨和舒尔茨，2023 年）。  
iii）知识增强：应用于完成对话、预测情感分布等任务中，并且通过与知识库整合来丰富大语言模型的情感内容（郑等人，2023 年；加涅和达扬，2023 年；孙等人，2023 年；郑（Jeong ）和马克（Mak ，原文此处不完整））。

## 2 具体论文
### 2.1 Sensation

1. Lynch 等人（2023）：引入了一种为查询大语言模型（LLMs）而设计的**结构化叙事提示**。该研究使用 OpenAI 的 ChatGPT **生成**叙事内容，然后使用卡方检验和费舍尔精确检验等统计测试，将这些叙事中的**情感水平**与真实推文进行**比较**。
2. Ratican 和 Hutson（2023）：提出了 **6DE 模型**，用于在大语言模型的情境中分析人类情感。该模型考虑了情感的多个维度，如唤醒度、效价、支配性、能动性、忠诚度和新颖性。
3. Zhang 等人（2023）：探索了四种提示策略，包括有上下文和无上下文的零样本和少样本提示，证明了这些提示在大语言模型的情感分析和识别任务中，相较于没有任何提示策略时表现良好。该研究强调了**上下文信息**在**提高**大语言模型**情感估计能力**方面的重要性。
4. Xu 等人（2023）：探索了**指令微调**，以提高大语言模型在心理健康预测方面的性能。经过微调的模型 Mental-Alpaca 和 Mental-FLAN-T5，尽管规模明显小于 GPT-3.5 和 GPT-4，但性能显著超越了它们。
5. Binz 和 Schulz（2023）：研究了用于微调大语言模型的心理学实验数据。这项研究展示了大语言模型在准确模仿人类行为方面的能力，并表明了在**微调过程中使用嵌入表示时**，大语言模型在**情感认知方面的潜力**。
6. Sun 等人（2023）：专注于通过**融入外部知识**来**增强共情响应**的生成。该研究引入了一种名为 CoNECT 的新方法，该方法利用情感指标来评估上下文相关性并促进共情推理。
7. Gagne 和 Dayan（2023）：探索了大语言模型生成文本的情感分布。这种方法通过利用特定的分位数，能够生成情感丰富的句子，展示了大语言模型在情感相关生成方面的有效性，并为理解大语言模型的内部机制提供了见解。

简而言之，当前在LLM的研究在处理情感文本输入方面取得了显着进步，主要是通过迅速的工程，嵌入式表示和知识增强。