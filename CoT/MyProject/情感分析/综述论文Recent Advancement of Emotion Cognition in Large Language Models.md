## 1. introduction
大语言模型（LLM）中的情绪认知对于提高各种应用程序的性能至关重要，例如社交媒体，人类计算机互动和心理健康评估。

我们探讨了当前的研究landscape，这些landscape主要围绕
1. 情绪分类
2. 情感丰富的反应产生
3. 心理评估理论

在本文中，我们详细介绍了<mark style="background: #FFB86CA6;">LLM在情绪认知中的最新进展的详细调查</mark>。探究了领域中研究的潜在研究方向，包括无监督的学习方法以及更复杂和<mark style="background: #FFB86CA6;">可解释的情感认知LLM的发展</mark>。我们还讨论了高级方法，例如用于提高LLM的情绪认知能力的对比学习

具有情感认知能力使LLM可以更加与人类价值观保持一致，从而增强其在情绪相关的下游任务中的表现。

一些挑战：
从LLM角度来讲：
1. 过度依赖注释数据
2. 难以处理复杂的情绪
3. 解释情绪认知中LLM的决策过程

从情绪分析上讲：
1. 问题的独特性，这表明文本中的情绪是抽象的，需要深刻的理解； 
2. 方法论复杂性，表明情绪超出了分类或产生，需要定制的策略和定量评估；
3. 任务的多样性，这表明情绪任务如问答和对话需要各种方法和有效性措施。

然后，我们在LLM中引入了两个典型的方向以进行情感认知：
1. 情绪评估
2. 情绪增强

情绪认知与人类情感心理学高度相关，不仅需要计算方法和技术，而且需要对心理理论的深刻理解和应用。

在我们的综述中，我们强调将心理学观点结合起来，特别是基于Ulric Neisser的认知心理学理论（Neisser，2014年）

贡献：
1. 从问题定义，方法论和应用领域的角度来看，我们对情绪认知的主要挑战进行了深入的分析。
2. 我们根据认知心理学理论的七个阶段将作品分类为情感领域，使特定任务与人类认知过程更好地保持一致。
3. 我们对情绪认知的未来研究方向进行了深入的讨论，旨在激发LLMS情感计算领域的进一步进步。

---
更具体的任务分类：
i）判别任务：包括在各种数据集上进行的情感分类和情感识别（张等人，2023 年；卡内罗斯 - 普拉多等人，2023 年；拉特杰等人，2023 年）。  
ii）生成任务：评估大语言模型的情感生成能力（林奇等人，2023 年；谢等人，2023 年；内森・克拉帕奇，2023 年）。  
iii）心理理论任务：关注大语言模型推断和复制人类心理状态的能力（特罗特等人，2023a；萨普等人，2022 年；甘地等人，2023 年）。  
iv）高阶任务：包括角色扮演、幽默理解、共情生成以及决策制定（江等人，2023 年；延奇和克尔斯廷，2023 年；李等人，2022 年；金等人，2022 年）。

对大语言模型的提升方法可分类如下：  
i）上下文学习：融入情感标签和上下文示例以提高情感识别能力（孙等人，2023 年；雷等人，2023 年；李等人，2022 年）。  
ii）微调：提升在心理健康预测和情感分析等任务中的表现（徐等人，2023 年；赫里和卡里米，2023 年；彭等人，2023 年；宾茨和舒尔茨，2023 年）。  
iii）知识增强：应用于完成对话、预测情感分布等任务中，并且通过与知识库整合来丰富大语言模型的情感内容（郑等人，2023 年；加涅和达扬，2023 年；孙等人，2023 年；郑（Jeong ）和马克（Mak ，原文此处不完整））。

## 2 具体论文
### 2.1 Sensation

Sensation是LLM在处理输入文本数据中表现出类似于人类的能力。该领域的工作主要关注输入形式。共同的输入表格包含三个类别，包括及时工程，嵌入式表示和知识增强。

1. Lynch 等人（2023）：引入了一种为查询大语言模型（LLMs）而设计的**结构化叙事提示**。该研究使用 OpenAI 的 ChatGPT **生成**叙事内容，然后使用卡方检验和费舍尔精确检验等统计测试，将这些叙事中的**情感水平**与真实推文进行**比较**。
2. <mark style="background: #FFB86CA6;">Ratican 和 Hutson（2023）</mark>：提出了 **6DE 模型**，用于在大语言模型的情境中分析人类情感。该模型考虑了情感的多个维度，如唤醒度、效价、支配性、能动性、忠诚度和新颖性。
3. <mark style="background: #FFB86CA6;">Zhang 等人（2023）</mark>：探索了四种提示策略，包括有上下文和无上下文的零样本和少样本提示，证明了这些提示在大语言模型的情感分析和识别任务中，相较于没有任何提示策略时表现良好。该研究强调了**上下文信息**在**提高**大语言模型**情感估计能力**方面的重要性。
4. <mark style="background: #FFB86CA6;">Xu 等人（2023）</mark>：探索了<mark style="background: #FFB86CA6;">指令微调</mark>，以提高大语言模型在心理健康预测方面的性能。经过微调的模型 Mental-Alpaca 和 Mental-FLAN-T5，尽管规模明显小于 GPT-3.5 和 GPT-4，但性能显著超越了它们。
5. Binz 和 Schulz（2023）：研究了用于微调大语言模型的心理学实验数据。这项研究展示了大语言模型在准确模仿人类行为方面的能力，并表明了在**微调过程中使用<mark style="background: #FFB86CA6;">嵌入表示</mark>时**，大语言模型在**情感认知方面的潜力**。
6. Sun 等人（2023）：专注于通过<mark style="background: #FFB86CA6;">融入外部知识</mark>来**增强共情响应**的生成。该研究引入了一种名为 CoNECT 的新方法，该方法利用情感指标来评估上下文相关性并促进共情推理。
7. Gagne 和 Dayan（2023）：探索了大语言模型生成文本的情感分布。这种方法通过利用特定的分位数，能够生成情感丰富的句子，展示了大语言模型在情感相关生成方面的有效性，并为理解大语言模型的内部机制提供了见解。

简而言之，当前在LLM的研究在处理情感文本输入方面取得了显着进步，主要是通过迅速的工程，嵌入式表示和知识增强。

### 2.2 Perception

Perception涉及解释和理解感官信息，处理从感官收集的原始数据以形成对外部世界的有意义的理解。 LLMS在情感认知方面的看法主要包含情感识别及其解释性。

情绪识别涉及在上下文或对话中识别情绪。例如，
- Rathje等。 （2023）探讨了GPT-3.5和GPT-4在检测各种语言心理结构（情绪，离散情绪和侵略性）时的表现，这表明LLM比基于字典的方法和微调的机器学习模型更准确。
- 张等。 （2023）证明LLM可以在情感识别任务中实现可比或卓越的表现，尤其是在识别少数情绪类别时； 
- Lei等。 （2023）介绍了Instructerc框架，这是一个有效的生成框架，采用了检索模块的组合和情感识别任务的组合； 
- Venkatakrishnan等。 （2023年）强调了在跨文化背景下情绪检测的重要性，研究了LLMS对诸如伊朗谋杀Zhina（Mahsa）Amini等重大事件的反应以及土耳其和叙利亚的地震； Rodríguez-Ibánez等。 （2023）社交网络中评估了情感分析方法及其在股票市场估值，政治和在线欺凌教育等领域的应用。该研究发现使用GPT-3和GPT-J等LLM的性能差，需要特定域的调整。 Peng等。 （2023）采用了深度及时的调整和低级别的适应，以调查LLM在语言情感识别方面的表现。在六个广泛使用的数据集中，改编后的LLM的令人印象深刻的性能突出了它们在情感识别方面的强大可传递性和可行性，超过了其他专业的深层模型。 Kheiri和Karimi（2023）讨论了使用LLM进行情感分析的潜力，表明LLMS在处理语言的细微差别方面表现出来以进行情感分析； Ullman（2023）强调了GPT-3.5在预测人类情绪方面的技巧，强调了其在理解和解释文本中情感内容方面的能力。 Carneros-Prado等。 （2023年）使用与COVID-19大流行有关的30,000个推文的数据集进行了GPT-3.5和IBM Watson之间的比较分析。这项研究揭示了LLM在情感分析和情感分类中的多面功能。但是，他们也很难将文本表达式纳入定义的情感类别。此外，幽默是情感认知方面更具挑战性的研究领域。 Trott等。 （2023b）研究GPT-3了解言语幽默的能力。实验表明，GPT-3在检测，欣赏和理解笑话的情况下表现出上述机会，尽管它与人类的表现不符。它表明，尽管LLM擅长掌握幽默，但仅语言就不足以完全开玩笑。图像也很有用。  情绪识别的解释性是通过单词，梯度，干扰的重量分布来对LLM的内部状态。 Kwon等。 （2022）通过比较基于评估特征和基于单词嵌入的相似性计算方法之间的性能，研究了表示情绪概念的方法。它发现GPT-3在基于单词的相似性计算中的表现优于基于单词的相似性计算，但也过分依赖于情感概念的估值。总的来说，LLM的最新进展集中在改善他们对文本中情绪的看法，反映了人类对情感细微差别的理解。虽然像GPT-3.5和GPT-4这样的LLM表现出在探索和解释各种环境中情绪的熟练程度，但它们在完全掌握情感的背景和微妙之处时仍面临挑战，突出了其感知能力的进一步增强，以实现其准确的情绪分类，理解的深度，理解的深度，了解域的适应能力和价值和价值和价值。

---

我们在本文中的全面评论重点介绍了情绪计算领域中LLM中情绪认知的重要性。我们
- 首先探讨情感认知中的关键挑战。
- 接下来，我们根据Ulric Neisser的认知心理学理论对当前的研究进行分类，从而在各个阶段提供了LLM中情绪处理的结构化摘要。这包括分析和讨论情绪分类，产生，可解释性以及将这些方面的整合到LLM中，以增强其同理心和认知能力。
- 之后，我们总结了当前研究的动机，方法，结果和可用工具，讨论了LLM的情绪认知的未来方向。
- 总体而言，我们为当前趋势和未来在情感认知的概述做出了贡献，期望使LLM与人类的情感和认知更加一致，从而更好地解决与情绪有关的下游任务。探索LLM的情绪认知能力可以通过改善情绪识别和响应产生来为进一步的研究提供信息，从而导致更准确的情感分析和同理心相互作用。这可以在将来增强教育，娱乐和客户服务方面的个性化用户体验。