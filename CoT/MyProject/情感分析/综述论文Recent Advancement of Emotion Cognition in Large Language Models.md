## 1. introduction
大语言模型（LLM）中的情绪认知对于提高各种应用程序的性能至关重要，例如社交媒体，人类计算机互动和心理健康评估。

我们探讨了当前的研究landscape，这些landscape主要围绕
1. 情绪分类
2. 情感丰富的反应产生
3. 心理评估理论

在本文中，我们详细介绍了<mark style="background: #FFB86CA6;">LLM在情绪认知中的最新进展的详细调查</mark>。探究了领域中研究的潜在研究方向，包括无监督的学习方法以及更复杂和<mark style="background: #FFB86CA6;">可解释的情感认知LLM的发展</mark>。我们还讨论了高级方法，例如用于提高LLM的情绪认知能力的对比学习

具有情感认知能力使LLM可以更加与人类价值观保持一致，从而增强其在情绪相关的下游任务中的表现。

一些挑战：
从LLM角度来讲：
1. 过度依赖注释数据
2. 难以处理复杂的情绪
3. 解释情绪认知中LLM的决策过程

从情绪分析上讲：
1. 问题的独特性，这表明文本中的情绪是抽象的，需要深刻的理解； 
2. 方法论复杂性，表明情绪超出了分类或产生，需要定制的策略和定量评估；
3. 任务的多样性，这表明情绪任务如问答和对话需要各种方法和有效性措施。

然后，我们在LLM中引入了两个典型的方向以进行情感认知：
1. 情绪评估
2. 情绪增强

情绪认知与人类情感心理学高度相关，不仅需要计算方法和技术，而且需要对心理理论的深刻理解和应用。

在我们的综述中，我们强调将心理学观点结合起来，特别是基于Ulric Neisser的认知心理学理论（Neisser，2014年）

贡献：
1. 从问题定义，方法论和应用领域的角度来看，我们对情绪认知的主要挑战进行了深入的分析。
2. 我们根据认知心理学理论的七个阶段将作品分类为情感领域，使特定任务与人类认知过程更好地保持一致。
3. 我们对情绪认知的未来研究方向进行了深入的讨论，旨在激发LLMS情感计算领域的进一步进步。

---
更具体的任务分类：
i）判别任务：包括在各种数据集上进行的情感分类和情感识别（张等人，2023 年；卡内罗斯 - 普拉多等人，2023 年；拉特杰等人，2023 年）。  
ii）生成任务：评估大语言模型的情感生成能力（林奇等人，2023 年；谢等人，2023 年；内森・克拉帕奇，2023 年）。  
iii）心理理论任务：关注大语言模型推断和复制人类心理状态的能力（特罗特等人，2023a；萨普等人，2022 年；甘地等人，2023 年）。  
iv）高阶任务：包括角色扮演、幽默理解、共情生成以及决策制定（江等人，2023 年；延奇和克尔斯廷，2023 年；李等人，2022 年；金等人，2022 年）。

对大语言模型的提升方法可分类如下：  
i）上下文学习：融入情感标签和上下文示例以提高情感识别能力（孙等人，2023 年；雷等人，2023 年；李等人，2022 年）。  
ii）微调：提升在心理健康预测和情感分析等任务中的表现（徐等人，2023 年；赫里和卡里米，2023 年；彭等人，2023 年；宾茨和舒尔茨，2023 年）。  
iii）知识增强：应用于完成对话、预测情感分布等任务中，并且通过与知识库整合来丰富大语言模型的情感内容（郑等人，2023 年；加涅和达扬，2023 年；孙等人，2023 年；郑（Jeong ）和马克（Mak ，原文此处不完整））。

## 2 具体论文
### 2.1 Sensation

Sensation是LLM在处理输入文本数据中表现出类似于人类的能力。该领域的工作主要关注输入形式。共同的输入表格包含三个类别，包括及时工程，嵌入式表示和知识增强。

1. Lynch 等人（2023）：引入了一种为查询大语言模型（LLMs）而设计的**结构化叙事提示**。该研究使用 OpenAI 的 ChatGPT **生成**叙事内容，然后使用卡方检验和费舍尔精确检验等统计测试，将这些叙事中的**情感水平**与真实推文进行**比较**。
2. <mark style="background: #FFB86CA6;">Ratican 和 Hutson（2023）</mark>：提出了 **6DE 模型**，用于在大语言模型的情境中分析人类情感。该模型考虑了情感的多个维度，如唤醒度、效价、支配性、能动性、忠诚度和新颖性。
3. <mark style="background: #FFB86CA6;">Zhang 等人（2023）</mark>：探索了四种提示策略，包括有上下文和无上下文的零样本和少样本提示，证明了这些提示在大语言模型的情感分析和识别任务中，相较于没有任何提示策略时表现良好。该研究强调了**上下文信息**在**提高**大语言模型**情感估计能力**方面的重要性。
4. <mark style="background: #FFB86CA6;">Xu 等人（2023）</mark>：探索了<mark style="background: #FFB86CA6;">指令微调</mark>，以提高大语言模型在心理健康预测方面的性能。经过微调的模型 Mental-Alpaca 和 Mental-FLAN-T5，尽管规模明显小于 GPT-3.5 和 GPT-4，但性能显著超越了它们。
5. Binz 和 Schulz（2023）：研究了用于微调大语言模型的心理学实验数据。这项研究展示了大语言模型在准确模仿人类行为方面的能力，并表明了在**微调过程中使用<mark style="background: #FFB86CA6;">嵌入表示</mark>时**，大语言模型在**情感认知方面的潜力**。
6. Sun 等人（2023）：专注于通过<mark style="background: #FFB86CA6;">融入外部知识</mark>来**增强共情响应**的生成。该研究引入了一种名为 CoNECT 的新方法，该方法利用情感指标来评估上下文相关性并促进共情推理。
7. Gagne 和 Dayan（2023）：探索了大语言模型生成文本的情感分布。这种方法通过利用特定的分位数，能够生成情感丰富的句子，展示了大语言模型在情感相关生成方面的有效性，并为理解大语言模型的内部机制提供了见解。

简而言之，当前在LLM的研究在处理情感文本输入方面取得了显着进步，主要是通过迅速的工程，嵌入式表示和知识增强。

### 2.2 Perception

Perception涉及解释和理解感官信息，处理从感官收集的原始数据以形成对外部世界的有意义的理解。 LLMS在情感认知方面的看法主要包含情感识别及其解释性。

1. Rathje 等人（2023）：探索了 GPT-3.5 和 GPT-4 在检测各种语言心理结构（情感、离散情感和攻击性）方面的性能，<mark style="background: #FFB86CA6;">表明大语言模型（LLMs）比基于词典的方法和微调的机器学习模型更准确</mark>。
2. Zhang 等人（2023）：证明了大语言模型在情感识别任务中可以达到相当或更优的性能，特别是在识别少数情感类别方面。
3. Lei 等人（2023）：引入了 InstructERC 框架，这是一个有效的生成框架，采用检索模块和情感对齐任务相结合的方式进行情感识别。
4. Venkatakrishnan 等人（2023）：强调了在跨文化背景下情感检测的重要性，研究了大语言模型对重大事件（如伊朗的 Zhina (Mahsa) Amini 被谋杀事件以及土耳其和叙利亚的地震）的反应。
5. Rodríguez-Ibánez 等人（2023）：评估了社交网络中的情感分析方法及其在股票市场估值、政治和网络欺凌教育等领域的应用。该研究发现使用如 GPT-3 和 GPT-J 等大语言模型时性能不佳，需要进行特定领域的调整。
6. Peng 等人（2023）：采用深度提示微调（deep prompt tuning）和低秩适应（low-rank adaptation）来研究大语言模型在语言情感识别方面的表现。经过适应的大语言模型在六个广泛使用的数据集上的出色表现，突出了它们在情感识别中的强大迁移能力和可行性，超越了其他专门的深度模型。
7. Kheiri 和 Karimi（2023）：讨论了使用大语言模型进行情感分析的潜力，表明大语言模型在处理情感分析中语言的细微差别方面表现出色。
8. Ullman（2023）：强调了 GPT-3.5 在预测人类情感方面的能力，突出了它在理解和解释文本中情感内容的能力。
9. Carneros-Prado 等人（2023）：使用一个包含 30,000 条与新冠疫情相关推文的数据集，对 GPT-3.5 和 IBM Watson 进行了比较分析。这项研究揭示了大语言模型在情感分析和情感分类方面的多方面能力，但它们在将文本表达归入定义的情感类别方面也存在困难。
10. Trott 等人（2023b）：研究了 GPT-3 理解言语幽默的能力。实验表明，GPT-3 在检测、欣赏和理解笑话方面的表现高于随机水平，尽管它还无法达到人类的表现。这表明虽然大语言模型擅长理解幽默，但仅靠语言不足以完全理解笑话，图像也很有用。
11. Kwon 等人（2022）：通过比较基于评估特征的相似度计算方法和基于词嵌入的相似度计算方法的性能，研究了表示情感概念的方法。研究发现，GPT-3 在基于词嵌入的相似度计算中表现更优，但也过度依赖于对情感概念的评估。

总的来说，LLM的最新进展集中在改善他们对文本中情绪的看法，反映了人类对情感细微差别的理解。虽然像GPT-3.5和GPT-4这样的LLM表现出在探索和解释各种环境中情绪的熟练程度，但它们在完全掌握情感的背景和微妙之处时仍面临挑战，突出了其感知能力的进一步增强，以实现其准确的情绪分类，理解的深度，理解的深度，了解域的适应能力和价值和价值和价值。

---

我们在本文中的全面评论重点介绍了情绪计算领域中LLM中情绪认知的重要性。我们
- 首先探讨情感认知中的关键挑战。
- 接下来，我们根据Ulric Neisser的认知心理学理论对当前的研究进行分类，从而在各个阶段提供了LLM中情绪处理的结构化摘要。这包括分析和讨论情绪分类，产生，可解释性以及将这些方面的整合到LLM中，以增强其同理心和认知能力。
- 之后，我们总结了当前研究的动机，方法，结果和可用工具，讨论了LLM的情绪认知的未来方向。
- 总体而言，我们为当前趋势和未来在情感认知的概述做出了贡献，期望使LLM与人类的情感和认知更加一致，从而更好地解决与情绪有关的下游任务。探索LLM的情绪认知能力可以通过改善情绪识别和响应产生来为进一步的研究提供信息，从而导致更准确的情感分析和同理心相互作用。这可以在将来增强教育，娱乐和客户服务方面的个性化用户体验。