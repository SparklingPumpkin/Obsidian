- 2023
- EMNLP会议(NLP顶会)
这篇论文（标题为《STORYANALOGY: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding》）由程佳阳等人撰写，发表于2023年EMNLP会议，研究了大型语言模型（LLMs）在故事层面类比推理（story-level analogy）上的能力，并首次构建了一个大规模的故事类比数据集STORYANALOGY。以下是对论文内容的详细介绍，涵盖其背景、方法、数据集、实验、结果、讨论和结论。

---

### **1. 引言与背景**

#### **1.1 研究背景**

- **类比推理的重要性**：类比推理是人类认知的核心能力，通过在不同领域或情境之间建立相似性映射（如“病毒入侵细胞”类比于“窃贼闯入房屋”），帮助理解复杂现象、解决问题和进行跨领域创新（Boden, 2009; Ding et al., 2023）。
- **研究空白**：尽管类比推理在人类认知中至关重要，但现有研究主要集中在词级类比（如“国王:男人::皇后:女人”），而对故事级类比（涉及完整叙事或事件序列的比较）研究较少，部分原因是缺乏大规模数据集和评估基准。
- **研究目标**：论文通过构建STORYANALOGY数据集（包含24,388个故事对），评估LLMs在故事级类比识别和生成上的能力，并探索通过微调和少样本学习（few-shot learning）提升模型表现。

#### **1.2 研究问题**

1. LLMs在故事级类比识别任务上的表现如何？
2. LLMs在故事级类比生成任务上的表现如何？
3. STORYANALOGY数据集能否通过微调或少样本学习提升LLMs的类比推理能力？

---

### **2. STORYANALOGY数据集**

#### **2.1 数据集概述**

- **规模与构成**：STORYANALOGY包含24,388个故事对，平均每个故事约20个词，涵盖四个领域：
    - **ProPara**（6,900对）：科学脚本，描述自然或科学过程（如“病毒入侵细胞”）。
    - **ROCStories**（4,900对）：社会常识故事，聚焦人类社交叙事。
    - **Word Analogy**（7,500对）：基于词级类比扩展的故事。
    - **ConceptNet**（5,000对）：基于常识知识图谱的三元组生成的故事。
- **标注**：每个故事对由Amazon Mechanical Turk的众包工作者基于扩展的结构映射理论（Structure-Mapping Theory, SMT）进行标注，评估两个维度的相似性：
    - **实体相似性（EntSim）**：故事中实体和主题的相似度，范围0（不相关）到3（几乎等同）。
    - **关系相似性（RelSim）**：故事中关系结构（如一阶关系：实体间谓词；二阶关系：事件间逻辑连接）的相似度，范围0（极差对齐）到3（完全对齐）。
- **类比分数（α）**：定义为α = RelSim / (1 + EntSim)，以强调高关系相似性和低实体相似性的类比特性，区分类比与字面相似性（literal similarity）。

#### **2.2 数据生成流程**

- **挑战**：故事级类比在通用语料库中稀少（仅约3%），直接检索成本高。
- **解决方案**：使用LLMs（具体为text-davinci-003）生成候选故事对：
    - **种子示例**：专家手动编写28个故事类比示例，覆盖多领域，确保多样性。
    - **生成方式**：
        1. **基于故事对生成**：给定源故事和种子示例，提示LLM生成目标故事。
        2. **基于词对生成**：从词级类比（如“词:语言::音符:音乐”）和种子示例生成源和目标故事。
    - **多样性控制**：从每个领域随机采样正交子主题，避免生成过于相似的故事。
- **质量控制**：通过众包标注过滤掉142个标注为“低质量”（如幻觉或有害内容）的故事对。

#### **2.3 标注过程**

- **资格筛选**：80个候选故事对由三位专家标注EntSim和RelSim，Spearman相关系数达89%-96%。众包工作者需与专家评分达到≥70%的Spearman相关性才能参与主轮标注。
- **主轮标注**：每对故事由5名合格工作者独立评分，采用平均分作为EntSim和RelSim。每轮后过滤低相关性工作者，确保标注质量。
- **一致性分析**：1,000个随机样本的Fleiss's kappa显示EntSim为47%，RelSim为42%，表明适中一致性。200个样本的专家与众包评分相关性为64.7%（EntSim）和69.9%（RelSim）。

#### **2.4 数据集分析**

- **分布特点**：ROCStories的EntSim和RelSim偏向较高值，反映其以人类社交叙事为主，可能导致类比任务更具挑战性（图3）。
- **划分**：每个领域随机抽取500对作为测试集，500对作为验证集，其余为训练集。

---

### **3. 方法与实验**

#### **3.1 类比识别实验**

- **任务**：评估模型预测EntSim、RelSim和类比分数α的能力。
- **评估方式**：
    1. **STS式评估**：计算模型预测相似性与标注分数的Spearman相关系数。
        - **编码器模型**：使用余弦相似性计算故事嵌入间的相似性（如RoBERTa、SimCSE、OpenAI-ada、DMR、RelBERT、GloVe）。
        - **LLMs**：提示模型直接预测EntSim和RelSim（使用长/短指令，0/1/3-shot设置）。
    2. **多选题评估**：从EntSim<1.0且RelSim>2.0的故事对中构建360个多选题，每个问题包含1个正确类比和3个负例（2个随机，1个高名词相似性但低词重叠的“难负例”）。
- **基线模型**：
    - **编码器模型**：包括未微调的RoBERTa、SimCSE、OpenAI-ada、DMR、RelBERT、GloVe（基于名词、动词或全词），以及微调的RoBERTa-Reg（回归）和RoBERTa-CL（对比学习）。
    - **LLMs**：FlanT5、LLaMa-65B、ChatGPT、GPT-3.5。
- **提示模板**：
    - **长指令**：包含EntSim和RelSim的详细定义。
    - **短指令**：仅提供评分标签。
    - **多选题模板**：要求选择与源故事最具类比性的候选故事（表3）。

#### **3.2 类比生成实验**

- **任务**：评估LLMs生成与源故事类比的目标故事的能力。
- **设置**：
    - **零样本（Zero-shot）**：仅提供源故事，提示生成类比故事。
    - **少样本（Few-shot）**：提供1-3个示例故事对。
    - **微调（Finetuned）**：在STORYANALOGY训练集上微调FlanT5，使用DeepSpeed加速。
- **评估指标**：
    - **类比性（Analogy）**：目标故事是否为源故事的类比。
    - **新颖性（Novelty）**：目标故事是否新颖（而非简单重复源故事）。
    - **合理性（Plausibility）**：目标故事是否合理且有意义。
    - 由Amazon Mechanical Turk的众包工作者评分，平均3人评分。

---

### **4. 结果**

#### **4.1 类比识别结果**

- **STS式评估（表2）**：
    - **人类表现**：EntSim（64.7%）、RelSim（69.9%）、α（62.5%）。
    - **编码器模型**：
        - 未微调模型在α上的表现较差（如SimCSE：1.5%，OpenAI-ada：0.7%），表明它们更适合字面相似性检索。
        - 关系感知模型（如DMR：11.4%，RelBERT：5.3%）在α上表现稍好。
        - 微调模型（RoBERTa-CL：23.2%，RoBERTa-Reg：17.0%）显著优于其他基线。
    - **LLMs**：
        - 整体表现较差（如ChatGPT：2.3%，FlanT5-xxl：4.7%）。
        - 长指令和3-shot设置略有提升，但仍远低于人类水平。
        - FlanT5-xxl在EntSim和RelSim预测上表现最佳。
    - **观察**：模型在单独预测EntSim和RelSim时表现尚可，但在预测α（需捕捉RelSim与EntSim的差距）时表现较差（图4）。
- **多选题评估（表4）**：
    - **人类表现**：85.6%。
    - **LLMs**：最佳模型（ChatGPT，3-shot，模板C）仅达47.9%，比人类低37.7%。
    - **基线模型**（FMQ/FMV，Sultan and Shahaf, 2023）：约44.7%-44.9%，仍远低于人类。
    - **观察**：难负例（高名词相似性）使任务更具挑战性，模型倾向于被表面相似性误导。

#### **4.2 类比生成结果（表6）**

- **零样本**：
    - ChatGPT（70.0%类比性，72.5%新颖性）和GPT-3.5（75.8%类比性，81.7%新颖性）表现优于FlanT5和LLaMa，后者常重复源故事模式。
    - 合理性普遍较高（>87.5%）。
- **少样本**：
    - LLaMa提升显著（类比性+28.4%，新颖性+27.5%）。
    - ChatGPT和GPT-3.5略有改善。
- **微调**：
    - 微调后的obligatory FlanT5-xxl（72.5%类比性，81.7%新颖性）媲美零样本ChatGPT，接近少样本ChatGPT和GPT-3.5。
    - 微调和少样本学习增加新颖性，但合理性略降，表明可能出现幻觉。

---

“

System: ### **5. 讨论**

#### **5.1 主要发现**

- **类比识别的挑战**：
    - LLMs和编码器模型在故事级类比识别任务上表现远逊于人类，特别是在捕捉类比分数α（高RelSim，低EntSim）时。
    - 模型倾向于优先考虑实体相似性（EntSim），而忽视关系相似性（RelSim），反映了在复杂关系推理上的局限性。
- **类比生成的潜力**：
    - 微调和少样本学习显著提升了模型生成类比的能力，尤其是FlanT5-xxl在微调后表现接近ChatGPT。
    - 然而，生成的新颖性提高可能导致合理性下降，表明幻觉问题需关注。
- **数据集的作用**：
    - STORYANALOGY数据集通过提供多样化的故事对和基于SMT的标注，有效促进了类比推理能力的评估和提升。

#### **5.2 α预测的难点**

- **原因分析**：
    - α（RelSim/EntSim）要求模型准确捕捉RelSim和EntSim的差距，而单独预测EntSim或RelSim相对简单。
    - 示例：若真实分数为EntSim=[2,1,3,0]，RelSim=[0,1,2,3]，预测分数为EntSim'=[0,2,3,0]，RelSim'=[1,0,2,1]，则α的Spearman相关性为0，尽管EntSim和RelSim的相关性分别为0.632和0.316。
    - 这表明模型在综合评估类比性时难以平衡两种相似性。

#### **5.3 相关工作对比**

- **词级类比**：如Mikolov等（2013）的词向量偏移方法，专注于简单关系类比，难以扩展到故事级。
- **句子/段落类比**：SME（Falkenhainer et al., 1989）和LRME（Turney, 2008）等方法通过网络挖掘解决类比检索，但缺乏大规模基准。
- **类比生成**：近期研究（如Bhavya et al., 2022）表明LLMs在词级类比生成上表现良好，但故事级类比仍具挑战性。

---

### **6. 结论与未来工作**

#### **6.1 结论**

- STORYANALOGY是首个大规模故事级类比数据集，为评估和提升LLMs的类比推理能力提供了重要资源。
- LLMs在故事级类比识别和生成任务上与人类表现存在较大差距，尤其在复杂关系推理上。
- 微调和少样本学习可显著提升模型性能，微调后的FlanT5-xxl表现接近ChatGPT，显示了数据驱动优化的潜力。
- 数据集的多样性和SMT扩展的应用为类比研究提供了新的视角。

#### **6.2 未来工作**

- **扩展任务类型**：探索其他类比任务，如跨模态类比（文本与图像）。
- **改进生成质量**：通过优化提示或正则化技术减少生成中的幻觉。
- **更广泛的模型测试**：评估更多LLMs和新型模型架构。
- **应用扩展**：将STORYANALOGY应用于类比挖掘（如艺术设计、科学研究）和类比推理增强（如知识库构建）。

---

### **7. 其他信息**

- **数据集与代码**：STORYANALOGY数据集和代码已公开（[https://github.com/loginaway/StoryAnalogy）。](https://github.com/loginaway/StoryAnalogy%EF%BC%89%E3%80%82)
- **出版信息**：发表于2023年EMNLP会议，页码11518-11537。
- **潜在应用**：
    - **类比挖掘**：支持艺术、设计和科学研究中的创新（如Hope et al., 2017）。
    - **类比推理**：提升LLMs在任务无关的推理能力，改善提示工程和知识库构建。

---

### **总结**

《STORYANALOGY》通过构建一个包含24,388个故事对的大规模数据集，填补了故事级类比研究的空白。论文展示了LLMs在类比识别和生成上的不足，尤其是在捕捉高关系相似性和低实体相似性的类比特性时。微调和少样本学习显著提升了模型性能，表明数据驱动的方法在类比推理中的潜力。未来，STORYANALOGY可作为类比推理研究的重要基准，推动LLMs在复杂认知任务上的发展。