### 研究背景

1. **领域及意义**：
    
    - 科学图形是研究成果传播的重要媒介。
    - 自动生成图形能够帮助研究人员节省设计时间，增强科学交流的视觉表现力。
2. **研究问题**：
    
    - 文本到图形生成与自然图像生成相比，面临着更多的挑战，例如：
        - 图形需要描述复杂的离散元素（如框、箭头、文本等）的关系。
        - 高度技术化的文本描述，图形风格、比例和文字渲染的多样性。

---

### 方法与技术

1. **核心方法：FigGen**：
    
    - 基于**扩散模型（Diffusion Models）**，采用潜变量表示（Latent Representation）。
    - 模型结构：
        - **图像自编码器（Image Autoencoder）**：用于将像素空间压缩至潜在表示，训练时优化KL损失和OCR感知损失。
        - **文本编码器（Text Encoder）**：基于BERT，自定义训练以适配技术性文本描述。
        - **扩散过程（Diffusion Process）**：通过时间条件和文本条件的去噪U-Net模型学习。
2. **数据集**：
    
    - 使用Paper2Fig100k数据集，包括81,194个训练样本和21,259个验证样本，涵盖多种图形样式和文本描述。
3. **训练与优化**：
    
    - 自编码器采用Adam优化器，学习率为4.5e-6。
    - 使用了NVIDIA V100和A100 GPU进行大规模并行训练。

---

### 实验结果

1. **生成质量**：
    
    - 提供了一些生成图的样例，展示了不同CFG（Classifier-Free Guidance）参数对生成图形质量的影响。
    - 结果表明，模型能够捕捉文本与图形之间的关系，但生成的图形质量尚不足以直接用于科研。
2. **定量评估**：
    
    - 通过FID（Fréchet Inception Distance）、IS（Inception Score）、KID（Kernel Inception Distance）和OCR-SIM等指标评估。
    - 更大的文本编码器和较高的CFG参数能够改善生成质量。

---

### 贡献与局限

1. **主要贡献**：
    
    - 定义了文本到科学图形生成的任务。
    - 提出了FigGen扩散模型，并展示了在Paper2Fig100k上的初步结果。
2. **当前局限**：
    
    - 文本与图形的对齐仍有挑战。
    - 缺乏适用于离散对象生成的验证指标和损失函数。
    - 图形生成的多样性和细节仍需要改进。

---

### 未来展望

- 优化模型以提升文本与图形的对齐能力。
- 设计更鲁棒的验证指标和生成目标函数。
- 探索在离散图形生成中的新型模型架构。