### 研究背景与动机

1. **重要性**：
    
    - 科学论文中的图表是传递复杂信息的重要工具，其标题对于解释图表内容至关重要。
    - 低质量的图表标题会降低读者对论文内容的理解。
2. **目标**：
    
    - 开发一个自动生成高质量科学图表标题的模型，提高学术交流效率。
    - 为视障读者提供辅助工具，使科学图表更易获取。

### 数据集构建（SCICAP）

1. **来源**：
    
    - 使用2010-2020年间发布在arXiv上的29万余篇计算机科学和机器学习领域的论文。
    - 提取了超过200万张图表及其对应的标题。
2. **数据预处理**：
    
    - **图表类型分类**：使用预训练模型分类图表类型（如折线图、柱状图等），重点研究占比最大的“折线图”。
    - **子图过滤**：去除包含子图的图表，仅保留单一图表。
    - **文本标准化**：对标题中的数字和公式等内容进行替换和规范化处理。
    - **标题选择**：根据标题的长度和句子数量生成不同数据子集。

### 实验设计与基线模型

1. **模型架构**：
    
    - 使用CNN+LSTM架构：
        - CNN（ResNet-101）作为图像编码器。
        - LSTM作为文本生成器，并加入注意力机制。
    - 探索三种特征输入：
        - 仅图像（Vision-Only）
        - 图像+文本（Vision+Text）
        - 仅文本（Text-Only）
2. **评价指标**：
    
    - 使用BLEU-4评分来衡量生成标题的质量。
3. **结果分析**：
    
    - 单句标题的模型表现最好（BLEU-4最高为0.0291），说明短标题更适合当前方法。
    - 图像与文本特征的结合未明显提升性能，这表明模型在多模态信息融合上仍有改进空间。

### 研究贡献

1. **数据集**：
    
    - 提出了一个大规模、开源的科学图表标题生成数据集（SCICAP），为后续研究奠定了基础。
2. **模型基线**：
    
    - 提供了基于经典神经网络模型的基线实验，验证了科学图表标题生成的可行性和挑战。

### 局限性与未来方向

1. **局限性**：
    
    - BLEU-4得分较低，说明生成标题的质量仍需提升。
    - 多模态特征未能显著改进结果，可能需要更先进的特征融合方法。
2. **未来方向**：
    
    - 引入大型预训练语言模型（如BERT变种）以提升生成质量。
    - 利用全文中的上下文信息进一步增强标题生成的准确性。

### 总结

该研究首次在科学图表标题生成领域提出了一个大规模的数据集和模型基线，揭示了当前方法的局限性及潜在改进空间，为学术界和工业界提供了宝贵的参考资源。